{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koQ-w1sV34sz"
   },
   "source": [
    "# Natural Language Processing\n",
    "## Assignment 4: Byte Pair Encoding\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "- 일반적으로 하나의 단어에 대해 하나의 embedding을 생성할 경우 out-of-vocabulary(OOV)라는 치명적인 문제를 갖게 됩니다. 학습 데이터에서 등장하지 않은 단어가 나오는 경우 Unknown token으로 처리해주어 모델의 입력으로 넣게 되면서 전체적으로 모델의 성능이 저하될 수 있습니다. 반면 모든 단어의 embedding을 만들기에는 필요한 embedding parameter의 수가 지나치게 많습니다.\n",
    "이러한 문제를 해결하기 위해 컴퓨터가 이해하는 단어를 표현하는 데에 데이터 압축 알고리즘 중 하나인 byte pair encoding 기법을 적용한 sub-word tokenizaiton이라는 개념이 나타났습니다. \n",
    "- 본 과제에서는 byte pair encoding을 이용한 간단한 sub-word tokenizer를 구현해봅니다.\n",
    "과제 노트북의 지시사항과 각 함수의 docstring과 [논문](https://arxiv.org/pdf/1508.07909.pdf)의 3페이지 algorithm 1 참고하여 build_bpe 함수를 완성하고 모든 test case를 통과해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNGuOpGM5VZD"
   },
   "source": [
    "## 2-1.build_bpe 함수를 완성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "9go8KbPe3s-L"
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set\n",
    "from itertools import chain\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "\n",
    "def get_stats(vocab):\n",
    "    pairs = defaultdict(int) \n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq \n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)') \n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word] \n",
    "    return v_out\n",
    "\n",
    "\n",
    "def build_bpe(\n",
    "        corpus: List[str],\n",
    "        max_vocab_size: int\n",
    ") -> List[int]:\n",
    "    \"\"\" BPE Vocabulary Builder\n",
    "    Implement vocabulary builder for byte pair encoding.\n",
    "    Please sort your idx2word by subword length in descending manner.\n",
    "\n",
    "    Hint: Counter in collection library would be helpful\n",
    "\n",
    "    Note: If you convert sentences list to word frequence dictionary,\n",
    "          building speed is enhanced significantly because duplicated words are\n",
    "          preprocessed together\n",
    "\n",
    "    Arguments:\n",
    "    corpus -- List of words to build vocab\n",
    "    max_vocab_size -- The maximum size of vocab\n",
    "\n",
    "    Return:\n",
    "    idx2word -- Subword list\n",
    "    \"\"\"\n",
    "    # Special tokens\n",
    "    PAD = BytePairEncoding.PAD_token  # Index of <PAD> must be 0\n",
    "    UNK = BytePairEncoding.UNK_token  # Index of <UNK> must be 1\n",
    "    CLS = BytePairEncoding.CLS_token  # Index of <CLS> must be 2\n",
    "    SEP = BytePairEncoding.SEP_token  # Index of <SEP> must be 3\n",
    "    MSK = BytePairEncoding.MSK_token  # Index of <MSK> must be 4\n",
    "    SPECIAL = [PAD, UNK, CLS, SEP, MSK]\n",
    "\n",
    "    WORD_END = BytePairEncoding.WORD_END  # Use this token as the end of a word\n",
    "    # YOUR CODE HERE   \n",
    "    idx2word = list(set(''.join(corpus))) + SPECIAL + [WORD_END]\n",
    "    word_cnt = Counter([word.replace(\"\",' ').lstrip() + WORD_END for word in corpus])\n",
    "\n",
    "    while len(idx2word) < max_vocab_size:\n",
    "        pair = get_stats(word_cnt)\n",
    "        try: \n",
    "            best = max(pair,key = pair.get)\n",
    "        except: \n",
    "            break\n",
    "        idx2word.append(''.join(best))\n",
    "        word_cnt = merge_vocab(best, word_cnt)\n",
    "    \n",
    "    return sorted(idx2word, key = len, reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBJnrNlY5cjW"
   },
   "source": [
    "## 2-2. build_bpe 함수 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ZG6-h8Wv5KWB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Building BPE Vocab Test Case======\n",
      "The first test passed!\n",
      "The second test passed!\n",
      "The third test passed!\n",
      "The forth test passed!\n",
      "The fifth test passed!\n",
      "All 5 tests passed!\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Helper functions below. DO NOT MODIFY!    #\n",
    "#############################################\n",
    "\n",
    "class BytePairEncoding(object):\n",
    "    \"\"\" Byte Pair Encoding class\n",
    "    We aren't gonna use this class for encoding. Because it is too slow......\n",
    "    We will use sentence piece Google have made.\n",
    "    Thus, this class is just for special token index reference.\n",
    "    \"\"\"\n",
    "    PAD_token = '<pad>'\n",
    "    PAD_token_idx = 0\n",
    "    UNK_token = '<unk>'\n",
    "    UNK_token_idx = 1\n",
    "    CLS_token = '<cls>'\n",
    "    CLS_token_idx = 2\n",
    "    SEP_token = '<sep>'\n",
    "    SEP_token_idx = 3\n",
    "    MSK_token = '<msk>'\n",
    "    MSK_token_idx = 4\n",
    "\n",
    "    WORD_END = '_'\n",
    "\n",
    "    def __init__(self, corpus: List[List[str]], max_vocab_size: int) -> None:\n",
    "        self.idx2word = build_bpe(corpus, max_vocab_size)\n",
    "\n",
    "    def encode(self, sentence: List[str]) -> List[int]:\n",
    "        return encode(sentence, self.idx2word)\n",
    "\n",
    "    def decoder(self, tokens: List[int]) -> List[str]:\n",
    "        return decode(tokens, self.idx2word)\n",
    "\n",
    "\n",
    "#############################################\n",
    "# Testing functions below.                  #\n",
    "#############################################\n",
    "\n",
    "\n",
    "def test_build_bpe():\n",
    "    print(\"======Building BPE Vocab Test Case======\")\n",
    "    PAD = BytePairEncoding.PAD_token\n",
    "    UNK = BytePairEncoding.UNK_token\n",
    "    CLS = BytePairEncoding.CLS_token\n",
    "    SEP = BytePairEncoding.SEP_token\n",
    "    MSK = BytePairEncoding.MSK_token\n",
    "    WORD_END = BytePairEncoding.WORD_END\n",
    "\n",
    "    # First test\n",
    "    corpus = ['abcde']\n",
    "    vocab = build_bpe(corpus, max_vocab_size=15)\n",
    "    assert vocab[:5] == [PAD, UNK, CLS, SEP, MSK], \\\n",
    "        \"Please insert the special tokens properly\"\n",
    "    print(\"The first test passed!\")\n",
    "\n",
    "    # Second test\n",
    "    assert sorted(vocab[5:], key=len, reverse=True) == vocab[5:], \\\n",
    "        \"Please sort your idx2word by subword length in decsending manner.\"\n",
    "    print(\"The second test passed!\")\n",
    "\n",
    "    # Third test\n",
    "    corpus = ['low'] * 5 + ['lower'] * 2 + ['newest'] * 6 + ['widest'] * 3\n",
    "    vocab = set(build_bpe(corpus, max_vocab_size=24))\n",
    "    assert vocab > {PAD, UNK, CLS, SEP, MSK, 'est_', 'low', 'newest_', \\\n",
    "                    'i', 'e', 'n', 't', 'd', 's', 'o', 'l', 'r', 'w',\n",
    "                    WORD_END} and \\\n",
    "           \"low_\" not in vocab and \"wi\" not in vocab and \"id\" not in vocab, \\\n",
    "        \"Your bpe result does not match expected result\"\n",
    "    print(\"The third test passed!\")\n",
    "\n",
    "    # forth test\n",
    "    corpus = ['aaaaaaaaaaaa', 'abababab']\n",
    "    vocab = set(build_bpe(corpus, max_vocab_size=13))\n",
    "    assert vocab == {PAD, UNK, CLS, SEP, MSK, 'aaaaaaaa', 'aaaa', 'abab', 'aa',\n",
    "                     'ab', 'a', 'b', WORD_END}, \\\n",
    "        \"Your bpe result does not match expected result\"\n",
    "    print(\"The forth test passed!\")\n",
    "\n",
    "    # fifth test\n",
    "    corpus = ['abc', 'bcd']\n",
    "    vocab = build_bpe(corpus, max_vocab_size=10000)\n",
    "    assert len(vocab) == 15, \\\n",
    "        \"Your bpe result does not match expected result\"\n",
    "    print(\"The fifth test passed!\")\n",
    "\n",
    "    print(\"All 5 tests passed!\")\n",
    "test_build_bpe()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bpe_camper.ipynb의 사본",
   "provenance": [
    {
     "file_id": "1Ue3inlDkAVEyLatLKGQ9iP3EIUG5dw9b",
     "timestamp": 1613649500726
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
